{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Harmonized View, Table, and Stream Creation\n",
    "#\n",
    "# This notebook creates harmonized views, tables, and streams from raw currency exchange data.\n",
    "\n",
    "# Environment variables - will be replaced by Jinja templating\n",
    "ENV = \"{{env}}\"\n",
    "RAW_SCHEMA = f\"{ENV}_RAW_SCHEMA\"\n",
    "HARMONIZED_SCHEMA = f\"{ENV}_HARMONIZED_SCHEMA\"\n",
    "\n",
    "# Use the current Snowflake session\n",
    "session = snowpark.session()\n",
    "\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.functions import col, min, max\n",
    "from snowflake.snowpark.window import Window\n",
    "from copy import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define raw data mapping\n",
    "raw_data = {\n",
    "    \"RAW_DAILY\": [\"RAW_DEXINUS\", \"RAW_DEXUSEU\", \"RAW_DEXUSUK\"],\n",
    "    \"RAW_MONTHLY\": [\"RAW_EXINUS\", \"RAW_EXUSEU\", \"RAW_EXUSUK\"]\n",
    "}\n",
    "\n",
    "def fill_missing_dates(df):\n",
    "    # Sort the dataframe by date\n",
    "    df = df.sort(col('\"date\"'))\n",
    "    \n",
    "    # Get min and max date from the dataset\n",
    "    date_range_df = df.agg(min(col('\"date\"')).alias(\"MIN_DATE\"), max(col('\"date\"')).alias(\"MAX_DATE\")).collect()\n",
    "    min_date, max_date = date_range_df[0][\"MIN_DATE\"], date_range_df[0][\"MAX_DATE\"]\n",
    "    print(min_date, max_date)\n",
    "\n",
    "    # Calculate the number of days between min_date and max_date\n",
    "    date_diff_query = f\"\"\"\n",
    "        SELECT DATEDIFF(DAY, '{min_date}', '{max_date}') AS date_diff\n",
    "    \"\"\"\n",
    "    date_diff_df = session.sql(date_diff_query).collect()\n",
    "    date_diff = date_diff_df[0][\"DATE_DIFF\"]\n",
    "\n",
    "    # Generate full date range using Snowflake's GENERATOR function\n",
    "    full_date_range_df = session.sql(f\"\"\"\n",
    "        SELECT CAST(DATEADD(DAY, SEQ4(), '{min_date}') AS DATE) AS date\n",
    "        FROM TABLE(GENERATOR(ROWCOUNT => {date_diff + 1}))\n",
    "    \"\"\")\n",
    "\n",
    "    # Perform left join to get missing dates and fill the missing ones with the last known value\n",
    "    df_with_full_dates = full_date_range_df.join(df, on=full_date_range_df[\"DATE\"] == df['\"date\"'], how=\"left\")\n",
    "    #df_with_full_dates.show(15)\n",
    "\n",
    "    # Define window specification\n",
    "    window_spec = Window.order_by(\"DATE\").rows_between(Window.UNBOUNDED_PRECEDING, Window.CURRENT_ROW)\n",
    "\n",
    "    # Apply the LAG function to fill missing values using the window spec\n",
    "    df_with_full_dates = df_with_full_dates.with_column(\n",
    "        '\"value\"',\n",
    "        F.coalesce(\n",
    "            col('\"value\"'),\n",
    "            F.last_value('\"value\"', True).over(window_spec)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Select only the \"DATE\" and \"value\" columns\n",
    "    df_with_full_dates = df_with_full_dates.select(col(\"DATE\").alias(\"DATE\"), col('\"value\"'))\n",
    "\n",
    "    # Final DataFrame sorted by date\n",
    "    final_df = df_with_full_dates.sort(col(\"DATE\"))\n",
    "    return final_df\n",
    "\n",
    "def create_harmonized_view():\n",
    "    session.use_schema(HARMONIZED_SCHEMA)\n",
    "\n",
    "    for schema_name, tables in raw_data.items():\n",
    "        base_df = None  # Initialize base DataFrame\n",
    "\n",
    "        for table in tables:\n",
    "            table_suffix = table.replace(\"RAW_\", \"\")  # Extract suffix (e.g., DEXINUS)\n",
    "            df = session.table(f\"{RAW_SCHEMA}.{table}\").select(F.col('\"date\"'), F.col('\"value\"'))\n",
    "\n",
    "            # Fill missing dates\n",
    "            if schema_name == \"RAW_DAILY\":\n",
    "                df = fill_missing_dates(df).select(F.col(\"DATE\").alias(\"DDATE\"), F.col('\"value\"').alias(table_suffix))\n",
    "                # Create a copy of df for the join to avoid self-join issue\n",
    "                df_copy = copy(df)\n",
    "                base_df = df_copy if base_df is None else base_df.join(df_copy, on=\"DDATE\", how=\"outer\")\n",
    "            else:\n",
    "                df = df.select(F.col('\"date\"').alias(\"MDATE\"), F.col('\"value\"').alias(table_suffix))\n",
    "                # Create a copy of df for the join to avoid self-join issue\n",
    "                df_copy = copy(df)\n",
    "                base_df = df_copy if base_df is None else base_df.join(df_copy, on=\"MDATE\", how=\"outer\")\n",
    "\n",
    "        # Apply UDF to specific columns\n",
    "        if schema_name == \"RAW_DAILY\":\n",
    "            base_df = base_df.with_column(\"DEXUSEU_CONVERTED\", F.call_udf(f\"{HARMONIZED_SCHEMA}.USD_CONVERSION_UDF\", F.col(\"DEXUSEU\")))\n",
    "            base_df = base_df.with_column(\"DEXUSUK_CONVERTED\", F.call_udf(f\"{HARMONIZED_SCHEMA}.USD_CONVERSION_UDF\", F.col(\"DEXUSUK\")))\n",
    "        else:\n",
    "            base_df = base_df.with_column(\"EXUSEU_CONVERTED\", F.call_udf(f\"{HARMONIZED_SCHEMA}.USD_CONVERSION_UDF\", F.col(\"EXUSEU\")))\n",
    "            base_df = base_df.with_column(\"EXUSUK_CONVERTED\", F.call_udf(f\"{HARMONIZED_SCHEMA}.USD_CONVERSION_UDF\", F.col(\"EXUSUK\")))\n",
    "\n",
    "        # Create view for daily and monthly separately\n",
    "        view_name = f\"HARMONIZED_{schema_name.split('_')[1]}_V\".upper()\n",
    "        base_df.create_or_replace_view(view_name)\n",
    "        print(f\"âœ… {view_name} created successfully!\")\n",
    "\n",
    "def create_harmonized_stream():\n",
    "    session.use_schema(HARMONIZED_SCHEMA)\n",
    "    \n",
    "    for schema_name in raw_data.keys():\n",
    "        if schema_name == \"RAW_DAILY\":\n",
    "            # Materialize the view into a table\n",
    "            session.sql(\"\"\"\n",
    "                CREATE OR REPLACE TABLE HARMONIZED_DAILY_TBL AS \n",
    "                SELECT * FROM HARMONIZED_DAILY_V\n",
    "            \"\"\").collect()\n",
    "            \n",
    "            # Create a stream on the materialized table\n",
    "            session.sql(\"\"\"\n",
    "                CREATE OR REPLACE STREAM HARMONIZED_DAILY_STREAM \n",
    "                ON TABLE HARMONIZED_DAILY_TBL \n",
    "                SHOW_INITIAL_ROWS = TRUE\n",
    "            \"\"\").collect()\n",
    "            print(\"Daily Stream created successfully!\")\n",
    "        \n",
    "        else:\n",
    "            # Materialize the view into a table\n",
    "            session.sql(\"\"\"\n",
    "                CREATE OR REPLACE TABLE HARMONIZED_MONTHLY_TBL AS \n",
    "                SELECT * FROM HARMONIZED_MONTHLY_V\n",
    "            \"\"\").collect()\n",
    "            \n",
    "            # Create a stream on the materialized table\n",
    "            session.sql(\"\"\"\n",
    "                CREATE OR REPLACE STREAM HARMONIZED_MONTHLY_STREAM \n",
    "                ON TABLE HARMONIZED_MONTHLY_TBL \n",
    "                SHOW_INITIAL_ROWS = TRUE\n",
    "            \"\"\").collect()\n",
    "            print(\"Monthly Stream created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Execute the functions\n",
    "create_harmonized_view()\n",
    "create_harmonized_stream()\n",
    "create_harmonized_combined_table()\n",
    "\n",
    "print(\"ðŸ”„ Harmonization process completed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
