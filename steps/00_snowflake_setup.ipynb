{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SET GITHUB_SECRET_USERNAME = 'sahilmutha1999';\n",
    "SET GITHUB_SECRET_PASSWORD = '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';\n",
    "SET GITHUB_URL_PREFIX = 'https://github.com/Damg7245-BigDataIntelligence';\n",
    "SET GITHUB_REPO_ORIGIN = 'https://github.com/Damg7245-BigDataIntelligence/FRED_Currency_Exchange.git';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "USE ROLE ACCOUNTADMIN; \n",
    "\n",
    "SET MY_USER = CURRENT_USER();\n",
    "CREATE OR REPLACE ROLE FRED_ROLE;\n",
    "GRANT ROLE FRED_ROLE TO ROLE SYSADMIN;\n",
    "GRANT ROLE FRED_ROLE TO USER IDENTIFIER($MY_USER);\n",
    "\n",
    "GRANT EXECUTE TASK ON ACCOUNT TO ROLE FRED_ROLE;\n",
    "GRANT MONITOR EXECUTION ON ACCOUNT TO ROLE FRED_ROLE;\n",
    "GRANT IMPORTED PRIVILEGES ON DATABASE SNOWFLAKE TO ROLE FRED_ROLE;\n",
    "\n",
    "-- Databases\n",
    "CREATE OR REPLACE DATABASE FRED_DB;\n",
    "GRANT OWNERSHIP ON DATABASE FRED_DB TO ROLE FRED_ROLE;\n",
    "\n",
    "-- Warehouses\n",
    "CREATE OR REPLACE WAREHOUSE FRED_WH WAREHOUSE_SIZE = XSMALL, AUTO_SUSPEND = 300, AUTO_RESUME= TRUE;\n",
    "GRANT OWNERSHIP ON WAREHOUSE FRED_WH TO ROLE FRED_ROLE;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "USE ROLE ACCOUNTADMIN;\n",
    "USE WAREHOUSE FRED_WH;\n",
    "USE DATABASE FRED_DB;\n",
    "\n",
    "CREATE OR REPLACE SCHEMA INTEGRATIONS;;\n",
    "CREATE OR REPLACE SCHEMA DEV_RAW_SCHEMA;\n",
    "CREATE OR REPLACE SCHEMA DEV_HARMONIZED_SCHEMA;\n",
    "CREATE OR REPLACE SCHEMA DEV_ANALYTICS_SCHEMA;\n",
    "CREATE OR REPLACE SCHEMA PROD_RAW_SCHEMA;\n",
    "CREATE OR REPLACE SCHEMA PROD_HARMONIZED_SCHEMA;\n",
    "CREATE OR REPLACE SCHEMA PROD_ANALYTICS_SCHEMA;\n",
    "\n",
    "\n",
    "USE SCHEMA INTEGRATIONS;\n",
    "\n",
    "CREATE OR REPLACE SECRET DEMO_GITHUB_SECRET\n",
    "  TYPE = password\n",
    "  USERNAME = $GITHUB_SECRET_USERNAME\n",
    "  PASSWORD = $GITHUB_SECRET_PASSWORD;\n",
    "\n",
    "CREATE OR REPLACE API INTEGRATION DEMO_GITHUB_API_INTEGRATION\n",
    "  API_PROVIDER = GIT_HTTPS_API\n",
    "  API_ALLOWED_PREFIXES = ($GITHUB_URL_PREFIX)\n",
    "  ALLOWED_AUTHENTICATION_SECRETS = (DEMO_GITHUB_SECRET)\n",
    "  ENABLED = TRUE;\n",
    "\n",
    "-- Git Repository\n",
    "CREATE OR REPLACE GIT REPOSITORY FRED_GIT_REPO\n",
    "  API_INTEGRATION = DEMO_GITHUB_API_INTEGRATION\n",
    "  GIT_CREDENTIALS = DEMO_GITHUB_SECRET\n",
    "  ORIGIN = $GITHUB_REPO_ORIGIN;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "USE ROLE ACCOUNTADMIN;\n",
    "USE WAREHOUSE FRED_WH;\n",
    "USE DATABASE FRED_DB;\n",
    "CREATE OR REPLACE SCHEMA EXTERNAL;\n",
    "\n",
    "CREATE OR REPLACE STORAGE INTEGRATION fred_s3_integration\n",
    "  TYPE = EXTERNAL_STAGE\n",
    "  STORAGE_PROVIDER = 'S3'\n",
    "  ENABLED = TRUE\n",
    "  STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::699475925561:role/snowflake_s3_role'\n",
    "  STORAGE_ALLOWED_LOCATIONS = ('s3://fredcurrencyexhange/');\n",
    "GRANT USAGE ON INTEGRATION fred_s3_integration TO ROLE FRED_ROLE;\n",
    "GRANT USAGE ON SCHEMA EXTERNAL TO ROLE FRED_ROLE;\n",
    "GRANT ALL PRIVILEGES ON SCHEMA FRED_DB.EXTERNAL TO ROLE FRED_ROLE;\n",
    "\n",
    "-- Create the file format\n",
    "USE ROLE FRED_ROLE;\n",
    "USE WAREHOUSE FRED_WH;\n",
    "USE DATABASE FRED_DB;\n",
    "USE SCHEMA EXTERNAL;\n",
    "\n",
    "CREATE OR REPLACE FILE FORMAT CSV_FORMAT \n",
    "TYPE = 'CSV' \n",
    "FIELD_OPTIONALLY_ENCLOSED_BY = '\"' \n",
    "PARSE_HEADER = TRUE;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SET env = 'DEV';\n",
    "\n",
    "USE ROLE ACCOUNTADMIN;\n",
    "USE WAREHOUSE FRED_WH;\n",
    "USE SCHEMA FRED_DB.INTEGRATIONS;\n",
    "\n",
    "EXECUTE IMMEDIATE FROM @FRED_GIT_REPO/branches/main/scripts/noteboook_deploy.sql\n",
    "    USING (env => $env, branch => 'main', schema1 => 'RAW_SCHEMA', schema2 => 'HARMONIZED_SCHEMA', schema3 => 'ANALYTICS_SCHEMA');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAG Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages from Snowflake's internal libraries\n",
    "from snowflake.core import Root\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "# Get the active session and set role, warehouse, and schema\n",
    "session = get_active_session()\n",
    "session.use_warehouse(\"FRED_WH\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your database and schema\n",
    "database_name = \"FRED_DB\"\n",
    "schema_name = \"INTEGRATIONS\"             # Using the INTEGRATIONS schema\n",
    "# Determine the environment based on schema name, defaulting to DEV unless it's explicitly PROD\n",
    "env = 'PROD' if schema_name.upper() == 'PROD_SCHEMA' else 'DEV'\n",
    "\n",
    "# Set the schema to use\n",
    "session.use_schema(f\"{database_name}.{schema_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SHOW NOTEBOOKS IN DATABASE FRED_DB;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DAG classes from Snowflake's internal DAG library\n",
    "from snowflake.core.task.dagv1 import DAGOperation, DAG, DAGTask\n",
    "from datetime import timedelta\n",
    "\n",
    "# Define your warehouse and DAG name\n",
    "warehouse_name = \"FRED_WH\"\n",
    "dag_name = \"FRED_DAG\"\n",
    "\n",
    "# Instantiate the API root and get the target schema object\n",
    "api_root = Root(session)\n",
    "schema = api_root.databases[database_name].schemas[schema_name]\n",
    "dag_op = DAGOperation(schema)\n",
    "target_schema1 = f\"{env}_RAW_SCHEMA\"\n",
    "target_schema2 = f\"{env}_HARMONIZED_SCHEMA\"\n",
    "target_schema3 = f\"{env}_ANALYTICS_SCHEMA\"\n",
    "\n",
    "# Define the DAG using the DAG API\n",
    "with DAG(dag_name, schedule=timedelta(days=1), warehouse=warehouse_name) as dag:\n",
    "    # Define tasks: each task runs a Snowflake notebook stored in your target schema.\n",
    "    # The notebook names are constructed based on the environment (DEV or PROD).\n",
    "    dag_task1 = DAGTask(\n",
    "        \"LOAD_RAW_DATA_TASK\", \n",
    "        definition=f'''EXECUTE NOTEBOOK \"{database_name}\".\"{target_schema1}\".\"{env}_load_raw_data\"()''', \n",
    "        warehouse=warehouse_name\n",
    "    )\n",
    "    dag_task2 = DAGTask(\n",
    "        \"HARMONIZE_DATA_TASK\", \n",
    "        definition=f'''EXECUTE NOTEBOOK \"{database_name}\".\"{target_schema2}\".\"{env}_harmonize_data\"()''', \n",
    "        warehouse=warehouse_name\n",
    "    )\n",
    "    dag_task3 = DAGTask(\n",
    "        \"ANALYTICS_TASK\", \n",
    "        definition=f'''EXECUTE NOTEBOOK \"{database_name}\".\"{target_schema3}\".\"{env}_analytics\"()''', \n",
    "        warehouse=warehouse_name\n",
    "    )\n",
    "    \n",
    "    # Define the dependencies between the tasks:\n",
    "    # LOAD_RAW_DATA_TASK must complete before HARMONIZE_DATA_TASK,\n",
    "    # which in turn must complete before ANALYTICS_TASK.\n",
    "    dag_task1 >> dag_task2 >> dag_task3\n",
    "\n",
    "# Deploy the DAG in Snowflake\n",
    "dag_op.deploy(dag, mode=\"orreplace\")\n",
    "\n",
    "# Optionally, iterate through deployed DAGs to verify the deployment\n",
    "dag_iter = dag_op.iter_dags(like='FRED_DAG%')\n",
    "for d in dag_iter:\n",
    "    print(d)\n",
    "\n",
    "# Optionally, run the DAG immediately\n",
    "# dag_op.run(dag)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
